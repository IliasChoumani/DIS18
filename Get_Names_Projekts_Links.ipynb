{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ermittlung Gepris-Personen-ID und Speicherung in einer Liste. Danach mit Hilfe der neuen Personen-Liste alle Projekte downloaden, die zu den jeweiligen Personen gehören. Ergebnisse werden in JSON-Dateien gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEPRIS ID Link für Förstner, Konrad: https://gepris.dfg.de/gepris/person/262159783\n",
      "GEPRIS ID Link für Becker, Anke: https://gepris.dfg.de/gepris/person/1592887\n",
      "GEPRIS ID Link für Bork, Peer: https://gepris.dfg.de/gepris/person/1011382\n",
      "GEPRIS ID Link für Clavel, Thomas: https://gepris.dfg.de/gepris/person/184220620\n",
      "GEPRIS ID Link für Goesmann, Alexander: https://gepris.dfg.de/gepris/person/188428736\n",
      "Daten für Person 'Professor Dr. Konrad  Förstner' erfolgreich in 'Professor-Dr-Konrad-Förstner.json' gespeichert.\n",
      "Daten für Person 'Professorin Dr. Anke  Becker' erfolgreich in 'Professorin-Dr-Anke-Becker.json' gespeichert.\n",
      "Daten für Person 'Professor Dr. Peer  Bork' erfolgreich in 'Professor-Dr-Peer-Bork.json' gespeichert.\n",
      "Daten für Person 'Professor Dr. Thomas  Clavel' erfolgreich in 'Professor-Dr-Thomas-Clavel.json' gespeichert.\n",
      "Daten für Person 'Professor Dr. Alexander  Goesmann' erfolgreich in 'Professor-Dr-Alexander-Goesmann.json' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re  # Regex-Modul zum Bereinigen des Dateinamens\n",
    "\n",
    "def get_gepris_id_for_person(name):\n",
    "    search_url = \"https://gepris.dfg.de/gepris/OCTOPUS\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    params = {\n",
    "        \"context\": \"person\",\n",
    "        \"task\": \"doSearchSimple\",\n",
    "        \"keywords_criterion\": name,\n",
    "        \"findButton\": \"historyCall\",\n",
    "        \"hitsPerPage\": 10,\n",
    "        \"index\": 0,\n",
    "        \"nurProjekteMitAB\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for bad responses\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the first search result link containing the name\n",
    "        search_results = soup.find_all(\"a\", href=True)\n",
    "        for result in search_results:\n",
    "            if name.lower() in result.text.lower():  # Case-insensitive comparison\n",
    "                return result['href']\n",
    "\n",
    "        print(f\"No GEPRIS ID found for {name}\")\n",
    "        return None\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error accessing GEPRIS for {name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Liste von Suchbegriffen für Personen\n",
    "search_terms = [\"Förstner, Konrad\", \"Becker, Anke\", \"Bork, Peer\", \"Clavel, Thomas\", \"Goesmann, Alexander\"]\n",
    "\n",
    "# Liste für die Ergebnisse initialisieren\n",
    "gepris_id_links = []\n",
    "\n",
    "# Durchlaufe jeden Suchbegriff und rufe die GEPRIS-ID ab\n",
    "for person_name in search_terms:\n",
    "    gepris_id_link = get_gepris_id_for_person(person_name)\n",
    "    if gepris_id_link:\n",
    "        # Vervollständige die URL mit dem Basis-Link, falls nötig\n",
    "        if not gepris_id_link.startswith(\"https://\"):\n",
    "            gepris_id_link = f\"https://gepris.dfg.de{gepris_id_link}\"\n",
    "        gepris_id_links.append(gepris_id_link)\n",
    "        print(f\"GEPRIS ID Link für {person_name}: {gepris_id_link}\")\n",
    "    else:\n",
    "        print(f\"GEPRIS ID Link für {person_name} konnte nicht gefunden werden.\")\n",
    "\n",
    "# Durchlaufe die Liste der GEPRIS-ID-Links\n",
    "for url in gepris_id_links:\n",
    "    try:\n",
    "        # Initialisiere ein leeres Dictionary für die Person und ihre Projekte\n",
    "        person_data = {}\n",
    "\n",
    "        # Führe eine HTTP-Anfrage durch, um den HTML-Inhalt der Seite zu erhalten\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Überprüfe, ob die Anfrage erfolgreich war (Status-Code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Parsen des HTML-Inhalts mit Beautiful Soup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Extrahiere den Namen der Person (aus dem Titel der Seite)\n",
    "            person_name = soup.title.text.strip().replace(\"DFG - GEPRIS - \", \"\")\n",
    "\n",
    "            # Bereinige den Personennamen für den Dateinamen (entferne Sonderzeichen und Leerzeichen)\n",
    "            clean_person_name = re.sub(r'[^\\w\\s-]', '', person_name).strip()\n",
    "            clean_person_name = re.sub(r'[-\\s]+', '-', clean_person_name)\n",
    "\n",
    "            # Füge den bereinigten Namen zur Personendaten hinzu\n",
    "            person_data[\"Person Name\"] = person_name\n",
    "\n",
    "            # Finde alle Links auf der Seite\n",
    "            links = soup.find_all('a', href=True)\n",
    "\n",
    "            # Filtere nur die Links, die auf Projekte verweisen\n",
    "            project_links = [link for link in links if '/gepris/projekt/' in link['href']]\n",
    "\n",
    "            # Extrahiere den Text (Namen) und den Link aus den gefundenen Projekt-Links\n",
    "            projects_data = []\n",
    "            for project_link in project_links:\n",
    "                project_name = project_link.get_text(strip=True)\n",
    "                project_url = project_link['href']\n",
    "                projects_data.append({\n",
    "                    \"Projekt Name\": project_name,\n",
    "                    \"Projekt Link\": project_url\n",
    "                })\n",
    "\n",
    "            # Füge die Projekte zum Dictionary der Person hinzu\n",
    "            person_data[\"Projekte\"] = projects_data\n",
    "\n",
    "            # Erstelle den Dateinamen mit dem bereinigten Personennamen\n",
    "            output_file = f\"{clean_person_name}.json\"\n",
    "\n",
    "            # Speichere die Daten in einer JSON-Datei mit dem entsprechenden Dateinamen\n",
    "            with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "                json.dump(person_data, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(f\"Daten für Person '{person_name}' erfolgreich in '{output_file}' gespeichert.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Fehler bei der Anfrage für {url}: {response.status_code}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Fehler bei der HTTP-Anfrage für {url}: {e}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Allgemeiner Fehler für {url}: {ex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alles unter hier drunter ist alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alle Projekt IDs von Professor Dr. Alexander Goesmann in GEPRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gepris/projekt/319835486\n",
      "/gepris/projekt/447603908\n",
      "/gepris/projekt/456668568\n",
      "/gepris/projekt/458957343\n",
      "/gepris/projekt/325443116\n",
      "/gepris/projekt/221270173\n",
      "/gepris/projekt/284237345\n",
      "/gepris/projekt/183605059\n",
      "/gepris/projekt/442032008\n",
      "/gepris/projekt/460129525\n",
      "/gepris/projekt/255821879\n",
      "/gepris/projekt/507302435\n",
      "/gepris/projekt/270041755\n",
      "/gepris/projekt/491261247\n"
     ]
    }
   ],
   "source": [
    "# URL der Website\n",
    "url = 'https://gepris.dfg.de/gepris/person/188428736'\n",
    "\n",
    "# Führe eine HTTP-Anfrage durch, um den HTML-Inhalt der Seite zu erhalten\n",
    "response = requests.get(url)\n",
    "\n",
    "# Überprüfe, ob die Anfrage erfolgreich war (Status-Code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parsen des HTML-Inhalts mit Beautiful Soup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Finde alle Links auf der Seite\n",
    "    links = soup.find_all('a', href=True)\n",
    "\n",
    "    # Filtere nur die Links, die auf Projekte verweisen\n",
    "    project_links = [link['href'] for link in links if '/gepris/projekt/' in link['href']]\n",
    "\n",
    "    # Drucke die gefundenen Projekt-Links\n",
    "    for project_link in project_links:\n",
    "        print(project_link)\n",
    "\n",
    "else:\n",
    "    print(f\"Fehler bei der Anfrage: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alle Namen der Projekte von Professor Dr. Alexander Goesmann in GEPRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core Unit - Genom Signaturen und integrierte Systembiologie der Pathogen-Wirts Interaktion\n",
      "Bioinformatische Methoden zur Analyse der mutualistischen RNA-Kommunikation\n",
      "Bioinformatische Workflows zur skalierbaren Analyse von pflanzlichen “Omics”-Daten in Cloud-Computing-Umgebungen\n",
      "Evolution von Gennetzwerken: Die Ranunculales als Modellordnung für evolutionäre Innovationen\n",
      "GRK 2355: Regulatorische Netzwerke im mRNA-Lebenszyklus:\n",
      "von kodierenden zu nichtkodierenden RNAs\n",
      "GRK 1906: Informatische Methoden für die Analyse von Genomdiversität und -dynamik\n",
      "KFO 309: Virus-induced Lung Injury:\n",
      "Pathobiology and Novel Therapeutic Strategies\n",
      "Bioinformatische Analyse genomweiter Datensätze\n",
      "NFDI4BioDiversität – Biodiversität, Ökologie und Umweltdaten\n",
      "NFDI4Microbiota - Nationale Forschungsdateninfrastruktur für Mikrobiota-Forschung\n",
      "Genom-weite Untersuchungen zur Artbildung unter sympatrischen Bedingungen in einem marinen Säuger: demographische Entwicklungsgeschichte, Populationsstruktur und lokale Anpassung im vom Aussterben bedrohten Galapagos Seelöwen\n",
      "Die Rolle von SOCS1 Mutationen bei der Pathogenese von Hodgkin Lymphomen und Diffus großzelligen B-Zell Lymphomen\n",
      "Nukleosom-Präservierung in Säugetier-Spermien: ein epigenetisches Programm zur Wahrung der gesunden männlichen Reproduktion\n",
      "Untersuchung der Mechanismen für die Stabilität von mcr-1-kodierenden IncX4-Mechanismen\n"
     ]
    }
   ],
   "source": [
    "# URL der Website\n",
    "url = 'https://gepris.dfg.de/gepris/person/188428736'\n",
    "\n",
    "# Führe eine HTTP-Anfrage durch, um den HTML-Inhalt der Seite zu erhalten\n",
    "response = requests.get(url)\n",
    "\n",
    "# Überprüfe, ob die Anfrage erfolgreich war (Status-Code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parsen des HTML-Inhalts mit Beautiful Soup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Finde alle Links auf der Seite\n",
    "    links = soup.find_all('a', href=True)\n",
    "\n",
    "    # Filtere nur die Links, die auf Projekte verweisen\n",
    "    project_links = [link for link in links if '/gepris/projekt/' in link['href']]\n",
    "\n",
    "    # Extrahiere den Text (Namen) aus den gefundenen Projekt-Links\n",
    "    project_names = [project_link.get_text(strip=True) for project_link in project_links]\n",
    "\n",
    "    # Drucke die gefundenen Projektnamen\n",
    "    for project_name in project_names:\n",
    "        print(project_name)\n",
    "\n",
    "else:\n",
    "    print(f\"Fehler bei der Anfrage: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alle Namen und Links der Projekte von Professor Dr. Alexander Goesmann in GEPRIS mit Name des Autors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projekt Name: Core Unit - Genom Signaturen und integrierte Systembiologie der Pathogen-Wirts Interaktion\n",
      "Link: /gepris/projekt/319835486\n",
      "\n",
      "Projekt Name: Bioinformatische Methoden zur Analyse der mutualistischen RNA-Kommunikation\n",
      "Link: /gepris/projekt/447603908\n",
      "\n",
      "Projekt Name: Bioinformatische Workflows zur skalierbaren Analyse von pflanzlichen “Omics”-Daten in Cloud-Computing-Umgebungen\n",
      "Link: /gepris/projekt/456668568\n",
      "\n",
      "Projekt Name: Evolution von Gennetzwerken: Die Ranunculales als Modellordnung für evolutionäre Innovationen\n",
      "Link: /gepris/projekt/458957343\n",
      "\n",
      "Projekt Name: GRK 2355: Regulatorische Netzwerke im mRNA-Lebenszyklus:\n",
      "von kodierenden zu nichtkodierenden RNAs\n",
      "Link: /gepris/projekt/325443116\n",
      "\n",
      "Projekt Name: GRK 1906: Informatische Methoden für die Analyse von Genomdiversität und -dynamik\n",
      "Link: /gepris/projekt/221270173\n",
      "\n",
      "Projekt Name: KFO 309: Virus-induced Lung Injury:\n",
      "Pathobiology and Novel Therapeutic Strategies\n",
      "Link: /gepris/projekt/284237345\n",
      "\n",
      "Projekt Name: Bioinformatische Analyse genomweiter Datensätze\n",
      "Link: /gepris/projekt/183605059\n",
      "\n",
      "Projekt Name: NFDI4BioDiversität – Biodiversität, Ökologie und Umweltdaten\n",
      "Link: /gepris/projekt/442032008\n",
      "\n",
      "Projekt Name: NFDI4Microbiota - Nationale Forschungsdateninfrastruktur für Mikrobiota-Forschung\n",
      "Link: /gepris/projekt/460129525\n",
      "\n",
      "Projekt Name: Genom-weite Untersuchungen zur Artbildung unter sympatrischen Bedingungen in einem marinen Säuger: demographische Entwicklungsgeschichte, Populationsstruktur und lokale Anpassung im vom Aussterben bedrohten Galapagos Seelöwen\n",
      "Link: /gepris/projekt/255821879\n",
      "\n",
      "Projekt Name: Die Rolle von SOCS1 Mutationen bei der Pathogenese von Hodgkin Lymphomen und Diffus großzelligen B-Zell Lymphomen\n",
      "Link: /gepris/projekt/507302435\n",
      "\n",
      "Projekt Name: Nukleosom-Präservierung in Säugetier-Spermien: ein epigenetisches Programm zur Wahrung der gesunden männlichen Reproduktion\n",
      "Link: /gepris/projekt/270041755\n",
      "\n",
      "Projekt Name: Untersuchung der Mechanismen für die Stabilität von mcr-1-kodierenden IncX4-Mechanismen\n",
      "Link: /gepris/projekt/491261247\n",
      "\n",
      "Name der Person: DFG - GEPRIS - Professor Dr. Alexander  Goesmann\n"
     ]
    }
   ],
   "source": [
    "# URL der Website\n",
    "url = 'https://gepris.dfg.de/gepris/person/188428736'\n",
    "\n",
    "# Führe eine HTTP-Anfrage durch, um den HTML-Inhalt der Seite zu erhalten\n",
    "response = requests.get(url)\n",
    "\n",
    "# Überprüfe, ob die Anfrage erfolgreich war (Status-Code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parsen des HTML-Inhalts mit Beautiful Soup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extrahiere den Namen der Person (aus dem Titel der Seite)\n",
    "    person_name = soup.title.text.strip()\n",
    "\n",
    "    # Finde alle Links auf der Seite\n",
    "    links = soup.find_all('a', href=True)\n",
    "\n",
    "    # Filtere nur die Links, die auf Projekte verweisen\n",
    "    project_links = [link for link in links if '/gepris/projekt/' in link['href']]\n",
    "\n",
    "    # Extrahiere den Text (Namen) und den Link aus den gefundenen Projekt-Links\n",
    "    for project_link in project_links:\n",
    "        project_name = project_link.get_text(strip=True)\n",
    "        project_url = project_link['href']\n",
    "        print(f\"Projekt Name: {project_name}\\nLink: {project_url}\\n\")\n",
    "\n",
    "    # Drucke den Namen der Person\n",
    "    print(f\"Name der Person: {person_name}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Fehler bei der Anfrage: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen einer Liste aller Ids der 10 Autoren welche in GEPRIS Projekte haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kein eintrag haben: jochen blom, Marius Dieckmann, Barbara Götz, Thomas Gübitz, Franziska Hufsky\n",
    "liste_aller_personen = [\"https://gepris.dfg.de/gepris/person/262159783\",\n",
    "                       \"https://gepris.dfg.de/gepris/person/1592887\",\n",
    "                       \"https://gepris.dfg.de/gepris/person/1011382\",\n",
    "                       \"https://gepris.dfg.de/gepris/person/184220620\",\n",
    "                        \"https://gepris.dfg.de/gepris/person/188428736\",       \n",
    "                       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen einer Json Datei mit allen 10 Autoren welche in GEPRIS Projekte haben, mit jeweiligen Projektnamen und Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Daten erfolgreich in 'output_all_persons_names_projects_links.json' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# Liste aller Personen-URLs\n",
    "liste_aller_personen = [\n",
    "    \"https://gepris.dfg.de/gepris/person/262159783\",\n",
    "    \"https://gepris.dfg.de/gepris/person/1592887\",\n",
    "    \"https://gepris.dfg.de/gepris/person/1011382\",\n",
    "    \"https://gepris.dfg.de/gepris/person/184220620\",\n",
    "    \"https://gepris.dfg.de/gepris/person/188428736\",\n",
    "]\n",
    "\n",
    "# Initialisiere eine leere Liste für alle Personen und ihre Projekte\n",
    "all_persons_data = []\n",
    "\n",
    "# Durchlaufe die Liste aller Personen\n",
    "for url in liste_aller_personen:\n",
    "    # Initialisiere ein leeres Dictionary für die Person und ihre Projekte\n",
    "    person_data = {}\n",
    "\n",
    "    # Führe eine HTTP-Anfrage durch, um den HTML-Inhalt der Seite zu erhalten\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Überprüfe, ob die Anfrage erfolgreich war (Status-Code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parsen des HTML-Inhalts mit Beautiful Soup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Extrahiere den Namen der Person (aus dem Titel der Seite)\n",
    "        person_name = soup.title.text.strip().replace(\"DFG - GEPRIS - \", \"\")\n",
    "        person_data[\"Person Name\"] = person_name\n",
    "\n",
    "        # Finde alle Links auf der Seite\n",
    "        links = soup.find_all('a', href=True)\n",
    "\n",
    "        # Filtere nur die Links, die auf Projekte verweisen\n",
    "        project_links = [link for link in links if '/gepris/projekt/' in link['href']]\n",
    "\n",
    "        # Extrahiere den Text (Namen) und den Link aus den gefundenen Projekt-Links\n",
    "        projects_data = []\n",
    "        for project_link in project_links:\n",
    "            project_name = project_link.get_text(strip=True)\n",
    "            project_url = project_link['href']\n",
    "            projects_data.append({\n",
    "                \"Projekt Name\": project_name,\n",
    "                \"Projekt Link\": project_url\n",
    "            })\n",
    "\n",
    "        # Füge die Projekte zum Dictionary der Person hinzu\n",
    "        person_data[\"Projekte\"] = projects_data\n",
    "\n",
    "        # Füge die Person zum Gesamtdictionary hinzu\n",
    "        all_persons_data.append(person_data)\n",
    "\n",
    "    else:\n",
    "        print(f\"Fehler bei der Anfrage für {url}: {response.status_code}\")\n",
    "\n",
    "# Speichere alle Daten in einer JSON-Datei\n",
    "with open('output_all_persons_names_projects_links.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(all_persons_data, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Drucke eine Bestätigungsmeldung\n",
    "print(\"Alle Daten erfolgreich in 'output_all_persons_names_projects_links.json' gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen von Json dateien welche die jeweilige Person und deren Projekte enthalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten für Person 'Professor Dr. Konrad  Förstner' erfolgreich in 'Professor-Dr-Konrad-Förstner.json' gespeichert.\n",
      "Daten für Person 'Professorin Dr. Anke  Becker' erfolgreich in 'Professorin-Dr-Anke-Becker.json' gespeichert.\n",
      "Daten für Person 'Professor Dr. Peer  Bork' erfolgreich in 'Professor-Dr-Peer-Bork.json' gespeichert.\n",
      "Daten für Person 'Professor Dr. Thomas  Clavel' erfolgreich in 'Professor-Dr-Thomas-Clavel.json' gespeichert.\n",
      "Daten für Person 'Professor Dr. Alexander  Goesmann' erfolgreich in 'Professor-Dr-Alexander-Goesmann.json' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re  # Regex-Modul zum Bereinigen des Dateinamens\n",
    "\n",
    "# Liste aller Personen-URLs\n",
    "liste_aller_personen = [\n",
    "    \"https://gepris.dfg.de/gepris/person/262159783\",\n",
    "    \"https://gepris.dfg.de/gepris/person/1592887\",\n",
    "    \"https://gepris.dfg.de/gepris/person/1011382\",\n",
    "    \"https://gepris.dfg.de/gepris/person/184220620\",\n",
    "    \"https://gepris.dfg.de/gepris/person/188428736\",\n",
    "]\n",
    "\n",
    "# Durchlaufe die Liste aller Personen\n",
    "for url in liste_aller_personen:\n",
    "    try:\n",
    "        # Initialisiere ein leeres Dictionary für die Person und ihre Projekte\n",
    "        person_data = {}\n",
    "\n",
    "        # Führe eine HTTP-Anfrage durch, um den HTML-Inhalt der Seite zu erhalten\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Überprüfe, ob die Anfrage erfolgreich war (Status-Code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Parsen des HTML-Inhalts mit Beautiful Soup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Extrahiere den Namen der Person (aus dem Titel der Seite)\n",
    "            person_name = soup.title.text.strip().replace(\"DFG - GEPRIS - \", \"\")\n",
    "\n",
    "            # Bereinige den Personennamen für den Dateinamen (entferne Sonderzeichen und Leerzeichen)\n",
    "            clean_person_name = re.sub(r'[^\\w\\s-]', '', person_name).strip()\n",
    "            clean_person_name = re.sub(r'[-\\s]+', '-', clean_person_name)\n",
    "\n",
    "            # Füge den bereinigten Namen zur Personendaten hinzu\n",
    "            person_data[\"Person Name\"] = person_name\n",
    "\n",
    "            # Finde alle Links auf der Seite\n",
    "            links = soup.find_all('a', href=True)\n",
    "\n",
    "            # Filtere nur die Links, die auf Projekte verweisen\n",
    "            project_links = [link for link in links if '/gepris/projekt/' in link['href']]\n",
    "\n",
    "            # Extrahiere den Text (Namen) und den Link aus den gefundenen Projekt-Links\n",
    "            projects_data = []\n",
    "            for project_link in project_links:\n",
    "                project_name = project_link.get_text(strip=True)\n",
    "                project_url = project_link['href']\n",
    "                projects_data.append({\n",
    "                    \"Projekt Name\": project_name,\n",
    "                    \"Projekt Link\": project_url\n",
    "                })\n",
    "\n",
    "            # Füge die Projekte zum Dictionary der Person hinzu\n",
    "            person_data[\"Projekte\"] = projects_data\n",
    "\n",
    "            # Erstelle den Dateinamen mit dem bereinigten Personennamen\n",
    "            output_file = f\"{clean_person_name}.json\"\n",
    "\n",
    "            # Speichere die Daten in einer JSON-Datei mit dem entsprechenden Dateinamen\n",
    "            with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "                json.dump(person_data, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(f\"Daten für Person '{person_name}' erfolgreich in '{output_file}' gespeichert.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Fehler bei der Anfrage für {url}: {response.status_code}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Fehler bei der HTTP-Anfrage für {url}: {e}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Allgemeiner Fehler für {url}: {ex}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatisiert mit Hilfe einer Liste, die Gepris-IDs der Forscher ermitteln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEPRIS ID Link für Förstner, Konrad: /gepris/person/262159783\n",
      "GEPRIS ID Link für Becker, Anke: /gepris/person/1592887\n",
      "GEPRIS ID Link für Bork, Peer: /gepris/person/1011382\n",
      "GEPRIS ID Link für Clavel, Thomas: /gepris/person/184220620\n",
      "GEPRIS ID Link für Goesmann, Alexander: /gepris/person/188428736\n",
      "Alle GEPRIS ID Links:\n",
      "['/gepris/person/262159783', '/gepris/person/1592887', '/gepris/person/1011382', '/gepris/person/184220620', '/gepris/person/188428736']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_gepris_id_for_person(name):\n",
    "    search_url = \"https://gepris.dfg.de/gepris/OCTOPUS\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    params = {\n",
    "        \"context\": \"person\",\n",
    "        \"task\": \"doSearchSimple\",\n",
    "        \"keywords_criterion\": name,\n",
    "        \"findButton\": \"historyCall\",\n",
    "        \"hitsPerPage\": 10,\n",
    "        \"index\": 0,\n",
    "        \"nurProjekteMitAB\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for bad responses\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the first search result link containing the name\n",
    "        search_results = soup.find_all(\"a\", href=True)\n",
    "        for result in search_results:\n",
    "            if name.lower() in result.text.lower():  # Case-insensitive comparison\n",
    "                return result['href']\n",
    "\n",
    "        print(f\"No GEPRIS ID found for {name}\")\n",
    "        return None\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error accessing GEPRIS for {name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Liste von Suchbegriffen für Personen\n",
    "search_terms = [\"Förstner, Konrad\", \"Becker, Anke\", \"Bork, Peer\", \"Clavel, Thomas\", \"Goesmann, Alexander\"]\n",
    "\n",
    "# Liste für die Ergebnisse initialisieren\n",
    "gepris_id_links = []\n",
    "\n",
    "# Durchlaufe jeden Suchbegriff und rufe die GEPRIS-ID ab\n",
    "for person_name in search_terms:\n",
    "    gepris_id_link = get_gepris_id_for_person(person_name)\n",
    "    if gepris_id_link:\n",
    "        gepris_id_links.append(gepris_id_link)\n",
    "        print(f\"GEPRIS ID Link für {person_name}: {gepris_id_link}\")\n",
    "    else:\n",
    "        print(f\"GEPRIS ID Link für {person_name} konnte nicht gefunden werden.\")\n",
    "\n",
    "# Ausgabe der gesamten Liste\n",
    "print(\"Alle GEPRIS ID Links:\")\n",
    "print(gepris_id_links)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
